{"cells":[{"cell_type":"markdown","metadata":{"id":"RfFiFANim4zV"},"source":["# Delineation of agricultural fields using SAMGEO\n","Contemporary agriculture faces many challenges growing population, climate changes, soil degradation and natural disacters. Due to all this challenges precise agriculture (PA) becomes crucial in agricultural fields monitoring, PA can help farmers in monitoring crops quality, soil moisture and can also optimise crops managment. Constant monitoring of agricultural fields is associated with necessity of defiying their boundaries. Manual defiying of crop fields boundaries using GIS tools can be time consuming, therefore application of machine learning models is gaining popularity.\n","\n","In this notebook I will show process of delineating crop fields boundaries using Segment Anything Model 2 and Samgeo package.\n","\n","To run this notebook make sure that you are using GPU, in Colab enviroment T4 GPU with 15 GB should be enought. To use fine-tuned SAM 2 models run SAM_Training notebook.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Cd0MU60YhTng"},"source":["## Install required packages\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sXrhxyN-SSUm"},"outputs":[],"source":["# Remove dev null redirection to print output\n","%pip install geedim &> /dev/null\n","%pip install segment-geospatial &> /dev/null\n","%pip install localtileserver &> /dev/null\n","%pip install PyCRS &> /dev/null"]},{"cell_type":"markdown","metadata":{"id":"TDj5s2kwfM40"},"source":["## Imoport packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eCY90P1LetyU"},"outputs":[],"source":["import os\n","import ee\n","import geemap\n","import geedim\n","import glob\n","import torch\n","import gc\n","import time\n","from google.colab import drive"]},{"cell_type":"markdown","metadata":{"id":"IGYk2_avfamu"},"source":["## Inicjalization of Google Earth Engine API\n","Inicjlize Google Earth Engine (GEE) to use their API for data computaions and access to GEE raster databases.\n","To inicjalize Google Earth Engine (GEE) mak sure that you have created poroject on [google cloud](https://console.cloud.google.com) platform that have GEE API enabled. Change project name to created by you."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dpb5PZBnewUZ"},"outputs":[],"source":["# Inicjalization of Google Earth Engine API\n","project_name = \"agriculture-delineation\" #@param\n","ee.Authenticate()\n","ee.Initialize(project=project_name)\n","\n","# Crate map\n","Map = geemap.Map()\n"]},{"cell_type":"markdown","metadata":{"id":"2Aa7Ar0XfvGM"},"source":["## Import SAMGEO packages\n","Samgeo packages have to be imported after map declaration, otherwise conflicts with geemap can ocure."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UFHYIhjdd4jG"},"outputs":[],"source":["from samgeo import tms_to_geotiff\n","from samgeo import SamGeo2\n","from samgeo import split_raster as sam_split_raster\n","import samgeo.common as common"]},{"cell_type":"markdown","source":["## What is SAMGEO\n","[Segment geospatial (SAMGEO)](https://samgeo.gishub.org/) is Python package for segmentation of satelite images with Segment Anything Model (SAM), it's developd by Dr. Qiusheng Wu. Main reason for Samgeo creation was to facilitate the use of SAM for geospatial data, Samgeo provide a straightforward interface to segment satelite data imagery and export it's results to various formats like vector or raster masks."],"metadata":{"id":"ZVUl0uWUwSem"}},{"cell_type":"code","source":["!pip show segment-geospatial"],"metadata":{"id":"nMtJ9TVvjbyp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gX-4OT55hawt"},"source":["## Define data download functions\n","Data is downloaded from database using GEE APi for Python. For segmentation purpose data from 3 raster images collection will be used:\n","\n","*   NAIP\n","*   Sentinel 2\n","*   Landsat\n"]},{"cell_type":"markdown","source":["### Sentinel 2\n","Sentinel 2A is European Space Agency optical imaging satellite, it was launched in 2015 as an part of Copernicus Programe. Images collected by Sentinel 2 are multi-spectral and pixels resolution starts from 10 meters. Pixels values are shifted by 10000, in newer images this value is equal 1000. Harmonised collection used in this notebook shifts data in newer scenes to range used in older scenes.\n","\n","Sentinel 2 image is loaded for GEE enviromet using ee.ImageCollection function, images are selected using given criteriums then pixels with clouds are masked using masking function. Clouds coverage information is store in QA60 band, 10 and 11 bits are related with cloud occurance. From images given bands are loaded and slected as mean value for all images. Pixels values are then divied by 10000 (the Sentinel 2 scale factor). Laslty image is cliped to boundaries of area of intrest."],"metadata":{"id":"yo0ceZmmP9KN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"tTQyns4mKF4y"},"outputs":[],"source":["def download_sentinel2_image(aoi, start_date, end_date, bands_list, clouds_percentage):\n","  \"\"\"\n","  Download Sentinel 2 image from Google Earth Engine.\n","\n","  Parametrs:\n","  aoi: geometry of area of interest, ee.Geometry\n","  start_date\n","  \"\"\"\n","\n","  def mask_clouds(image):\n","    \"\"\"\n","    Mask clouds on Sentinel 2 image.\n","\n","    Arguments:\n","    image: image to be remove clouds from\n","\n","    Returns\n","    image: image without clouds\n","    \"\"\"\n","\n","    # Select Sentinel 2 quality band\n","    qa = image.select(\"QA60\")\n","\n","    # Dfine mask for clouds (10 bit) and cirruses (bit 11)\n","    cloud_bit_mask = 1 << 10\n","    cirrus_bit_mask = 1 << 11\n","\n","    # Value 0 - no clouds and cirrues\n","    mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(qa.bitwiseAnd(cirrus_bit_mask).eq(0))\n","\n","    return image.updateMask(mask)\n","\n","\n","  # Download image as a median from collection\n","  image = (ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n","    .filterMetadata('CLOUDY_PIXEL_PERCENTAGE', 'less_than', clouds_percentage)\n","    .filterDate(start_date, end_date)\n","    .filterBounds(aoi)\n","    .map(mask_clouds)\n","    .select(bands_list)\n","    .median()\n","  )\n","\n","  # Divide image by Sentinel 2 scale factor\n","  rescale_image = image.divide(10000)\n","\n","  # Clip image to area of intrest\n","  clip_rescale_image = rescale_image.clip(aoi)\n","\n","  return clip_rescale_image\n","\n"]},{"cell_type":"markdown","source":["### Landsat 8\n","Landsat 8 is USA satelite launched in 2013 and collecting data across the world. Landsat 8 measures reflected electromagntic wave information in various bands using buildin sensors, base spatial resolution of pixels is 30 meters.\n","\n","Loading process of Landsat 8 image starts by defiying function applying scale factor to pixels values. Landsat optical bands pixels are multiply by 0.0000275 and -0.2 is added. To ensure image quality clouds masking function is needed, Landsat images comes with special quality ansurance (QA) band in which information of cloud occurance is stored. While image is loaded for GEE boath scale factor and cloud masking functions are used, then give image bands are selected as mean value of pixels. At the end whole image is cliped to area of intrest."],"metadata":{"id":"VxElYTD4SG4Z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SyEaHkgqI8gN"},"outputs":[],"source":["def download_landsat8_image(aoi, start_date, end_date, bands_list, clouds_percentage):\n","  \"\"\"\n","  Download Landsat 8 image from Google Earth Engine.\n","\n","  Parametrs:\n","  aoi: geometry of area of interest, ee.Geometry\n","  start_date: date to start search for images\n","  end_date: date to end search for images\n","  bands_list: list of bands to be downloaded\n","  clouds_percentage: percentage of clouds in image\n","  \"\"\"\n","\n","  def apply_scale_factors(image):\n","    \"\"\"\n","    Scale image by Landsat 8 bands scales.\n","\n","    image: landsat image, ee.image\n","    \"\"\"\n","\n","    # Scale image by Landsat 8 bands scales.\n","    optical_bands = image.select('SR_B.*').multiply(0.0000275).add(-0.2)\n","    thermal_bands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n","\n","    # Add scaled bands to iamge\n","    return image.addBands(optical_bands, None, True).addBands(thermal_bands, None, True)\n","\n","  def mask_clouds(image):\n","    \"\"\"\n","    Mask clouds and shadows on Landsat 8 image using QA_PIXEL band.\n","\n","    image: landsat image, ee.image\n","    \"\"\"\n","    qa = image.select(\"QA_PIXEL\")\n","\n","    # Define masks for clouds (bit 3) and their shadows (bit 4)\n","    cloud_bit_mask = 1 << 3\n","    cloud_shadow_bit_mask = 1 << 4\n","\n","    # Value 0: no clouds and shadows\n","    cloud_mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(qa.bitwiseAnd(cloud_shadow_bit_mask).eq(0))\n","\n","    return image.updateMask(cloud_mask)\n","\n","\n","  # Landsat 8 Collection 2, Tier 1, Level-2\n","  dataset = (ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n","    .filterDate(start_date, end_date)\n","    .filterBounds(aoi)\n","    .map(mask_clouds)\n","    .map(apply_scale_factors)\n","    .select(bands_list)\n","    .median()\n","  )\n","\n","  # Clip image to aoi\n","  clip_rescale_image = dataset.clip(aoi)\n","\n","  return clip_rescale_image\n"]},{"cell_type":"markdown","source":["### NAIP\n","Image from USA National Agriculture Imagery Program collecting high resolution Airborne images. Images since 2018 comes in 0.6 meters resoultion and include 4 bands (RGBN), before 2018 data was collected only in reslution of 1 or 2 meters with RGB bands. NAIP images quailty is controled by automate and visuall methods.\n","\n","NAIP data is loaded from GEE enviroment as median value, image is then cliped to area of intrest boundaries and converted to unsigned int 8."],"metadata":{"id":"HNI5qvQOQJSa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gnqv6NDUvrpS"},"outputs":[],"source":["def download_naip_image(aoi, start_date, end_date, bands_list):\n","  \"\"\"\n","  Download USA National Agriculture Imagery Program (NAIP) image from Google Earth Engine.\n","\n","  aoi: geometry of area of interest, ee.Geometry\n","  start_date: date to start search for images, min 2002-06-15\n","  end_date: date to end search for images, max 2023-11-01\n","  bands_list: list of bands to be downloaded, available [\"R\", \"G\", \"B\", \"N\"]\n","  \"\"\"\n","\n","  # NAIP\n","  dataset = (ee.ImageCollection('USDA/NAIP/DOQQ')\n","    .filterDate(start_date, end_date)\n","    .filterBounds(aoi)\n","    .select(bands_list)\n","    .median()\n","  )\n","\n","  # Clip image to aoi\n","  clip_rescale_image = dataset.clip(aoi)\n","\n","  cast_image = clip_rescale_image.toUint8()\n","\n","  return cast_image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HJVqql1PD1sD"},"outputs":[],"source":["#@title save image function\n","def save_ee_image(image, file_path, scale, aoi, convert_to_int=True):\n","  \"\"\"\n","  Save ee.image as GeoTIFF.\n","\n","  image: ee.image to be downloaded\n","  file_path: path to save imge\n","  scale: scale to rescale image\n","  aoi: geometry of area of interest, ee.Geometry\n","  convert_to_int: convert image to uint8\n","  \"\"\"\n","\n","  # Get image crs code\n","  crs = image.select(0).projection().crs().getInfo()\n","\n","  # Convrt image to uint8 if nesesary\n","  if convert_to_int:\n","    image = image.multiply(255).uint8()\n","\n","  geemap.download_ee_image(\n","    image = image,\n","    filename = file_path + \".tif\",\n","    scale = scale,\n","    region = aoi,\n","    crs = crs\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sRCZBJF0ooFE"},"outputs":[],"source":["#@title Split raster function\n","def split_raster(file_path, out_dir, tile_size):\n","  \"\"\"\n","  Split image into smaller tiles.\n","\n","  file_path: path to image, str\n","  out_dir: path to save tiles, str\n","  tile_size: size of tile in pixels, tuple\n","  \"\"\"\n","\n","  # Split image into smaller tiles\n","  split_raster(\n","    filename = file_path,\n","    out_dir = out_dir,\n","    tile_size = tile_size\n","  )"]},{"cell_type":"markdown","source":["## Area of intrest\n","Chosen area of intrest for this analysis is located in Illinois, 30 km west of Chicago. AOI represents part of Illinois agricuture region, aoi covers aproximetly 139 km<sup>2</sup>."],"metadata":{"id":"b6p8vjshP7WN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ih8Mt3w3HTta"},"outputs":[],"source":["aoi_usa = ee.Geometry.Polygon([\n","    [[-88.95, 41.8],\n","    [-88.80, 41.8],\n","    [-88.80, 41.9],\n","    [-88.95, 41.9],\n","    [-88.95, 41.8]]\n","]);\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EEvjw6LDlhrz"},"source":["## Download data\n","To download data first required directories are created. Directory have following scheme:\n","```\n","content\n","├───naip\n","│   ├───images\n","│   ├───masks\n","│   └───tiles\n","...\n","```\n","\n","Once direstories are created data from all sources is downloaded. Date filter is set from 2020-01-01 to 2021-12-31, all images are selected as RGB bands and max cloud coverage is set to 20%. NAIP images are cut to 3000 px tiles, Sentinel to 500 px and Landsat to 1000 px."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GhF8YgiWUtgP"},"outputs":[],"source":["os.makedirs(\"sentinel/images\", exist_ok=True)\n","os.makedirs(\"sentinel/masks\", exist_ok=True)\n","os.makedirs(\"sentinel/tiles\", exist_ok=True)\n","\n","os.makedirs(\"landsat/images\", exist_ok=True)\n","os.makedirs(\"landsat/masks\", exist_ok=True)\n","os.makedirs(\"landsat/tiles\", exist_ok=True)\n","\n","os.makedirs(\"naip/images\", exist_ok=True)\n","os.makedirs(\"naip/masks\", exist_ok=True)\n","os.makedirs(\"naip/tiles\", exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0EU5DssCyJrC"},"outputs":[],"source":["#@title NAIP\n","image_naip_rgb = download_naip_image(aoi_usa, '2020-01-01', '2021-12-31', ['R', 'G', 'B'])\n","\n","save_ee_image(image_naip_rgb, \"naip/images/rgb_usa\", scale=0.6, aoi=aoi_usa, convert_to_int=False)\n","sam_split_raster(filename = \"naip/images/rgb_usa.tif\", out_dir = \"naip/tiles/rgb_usa\", tile_size = (3000, 3000), overlap=True)"]},{"cell_type":"code","source":["#@title Sentinel\n","image_sentinel_rgb = download_sentinel2_image(aoi_usa, '2020-01-01', '2021-12-31', ['B4', 'B3', 'B2'], 20)\n","\n","save_ee_image(image_sentinel_rgb, \"sentinel/images/rgb_usa\", 10, aoi_usa)\n","sam_split_raster(filename = \"sentinel/images/rgb_usa.tif\", out_dir = \"sentinel/tiles/rgb_usa\", tile_size = (500, 500), overlap=True)"],"metadata":{"id":"kNFwycv7Kvy0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Landsat\n","image_landsat_rgb = download_landsat8_image(aoi_usa, '2020-01-01', '2021-12-31', ['SR_B4', 'SR_B3', 'SR_B2'], 20)\n","\n","save_ee_image(image_landsat_rgb, \"landsat/images/rgb_usa\", 30, aoi_usa)\n","sam_split_raster(filename = \"landsat/images/rgb_usa.tif\", out_dir = \"landsat/tiles/rgb_usa\", tile_size = (1000, 1000), overlap=True)\n"],"metadata":{"id":"WqreAoJTZVYu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Images visualization"],"metadata":{"id":"bZ8-hx2WMa88"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkMwLX5cUTmk"},"outputs":[],"source":["vis_params= {\n","  'min': 0,\n","  'max': 1,\n","  'gamma': 2\n","}\n","\n","\n","vis_params_polygon = {\n","    \"color\": \"000000\",\n","    \"fillColor\": \"4d486a\",\n","    \"colorOpacity\": 1,\n","    \"width\": 2,\n","    \"lineType\": \"solid\",\n","    \"fillColorOpacity\": 1,\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lrh3ZibWRQoW"},"outputs":[],"source":["Map.addLayer(image_naip_rgb, {'bands': ['R', 'G', 'B'], 'min': 0, 'max': 255}, 'NAIP_rgb')\n","Map.addLayer(image_sentinel_rgb, vis_params, 'Sentinel_rgb')\n","Map.addLayer(image_landsat_rgb, vis_params, 'Landsat_rgb')\n","\n","Map.centerObject(aoi_usa, 12)\n","Map"]},{"cell_type":"markdown","source":["## Segmentation and delineation\n","\n"],"metadata":{"id":"Ja0289SkMliC"}},{"cell_type":"markdown","source":["First SAM 2 segmentation and delineation helper function is defined. This function loads all images paths from given directories and for every of them generates mask. If mask is not empty it will be saved under output path, then GPU memory is cleaned. Once all images are procesed segmentation masks are merged and vertorised into seperated files."],"metadata":{"id":"LsgmDQDGjaJ4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"lrFokL7UNrEo"},"outputs":[],"source":["from tqdm import tqdm\n","\n","def sam_generate_batch(sam, in_dir, out_dir, merge=True, vectorize=False):\n","  \"\"\"\n","  Segments all images located in given directory, final results can be merged and vectorised.\n","\n","  sam: sam 2 model to be used\n","  in_dir: path where images are located\n","  out_dir: path to store results\n","  merge: whether to merge masks\n","  vectorize: whether to vectorize masks\n","  \"\"\"\n","\n","  # Get all files in directory\n","  tif_files = glob.glob(os.path.join(in_dir, '*.tif'))\n","  # Make output directoryl\n","  os.makedirs(out_dir, exist_ok=True)\n","\n","\n","  for i, file in enumerate(tqdm(tif_files, desc=\"Processing TIFF files\")):\n","    #  Generate mask\n","    sam.generate(file)\n","\n","    # Check if mask is area is not 0\n","    if len(sam.masks) > 0 and sam.masks[0]['segmentation'].size > 0:\n","      # Save mask\n","      if out_dir is not None:\n","        sam.save_masks(output= out_dir + \"/mask_\" + str(i) + \".tif\")\n","      else:\n","        sam.save_masks(output= \"mask_\" + str(i) + \".tif\")\n","\n","    # Clean GPU memory\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","  # Merge mask\n","  if merge:\n","    print(f\"Merging masks\")\n","    common.merge_rasters(out_dir, output= out_dir + \"/merged_masks.tif\")\n","\n","  # Vectroise mask\n","  if vectorize:\n","    print(f\"Vectorizing masks\")\n","    common.raster_to_vector(out_dir + \"/merged_masks.tif\", output= out_dir + \"/merged_masks.shp\")\n","\n","  # Clean GPU memory\n","  gc.collect()\n","  torch.cuda.empty_cache()\n"]},{"cell_type":"markdown","source":["Connect to drive to load fine-tuned model weights and create directories to store results data."],"metadata":{"id":"uqO2ZVgai0_m"}},{"cell_type":"code","source":["# Connect to drive\n","drive.mount('/content/gdrive', force_remount=True)\n","\n","# Load finetune model weights\n","finetuned_tiny = torch.load(\"/content/gdrive/MyDrive/SAM_trained_models/fine_tuned_sam2_tiny_epoch_14.torch\")\n","finetuned_small = torch.load(\"/content/gdrive/MyDrive/SAM_trained_models/fine_tuned_sam2_small_epoch_14.torch\")\n","finetuned_base_plus = torch.load(\"/content/gdrive/MyDrive/SAM_trained_models/fine_tuned_sam2_base_epoch_14.torch\")\n","finetuned_large = torch.load(\"/content/gdrive/MyDrive/SAM_trained_models/fine_tuned_sam2_large_epoch_14.torch\")\n","\n","# Make directories to store results\n","!mkdir -p /content/gdrive/MyDrive/Agriculture_tif\n","!mkdir -p /content/gdrive/MyDrive/Agriculture_shp\n"],"metadata":{"id":"8tkCZKsO4tj3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Setup Samgeo\n","\n","\n"],"metadata":{"id":"kDKtiYs7XMEG"}},{"cell_type":"markdown","source":["Choose SAM 2 pretrained model checkpoint or fine-tuned. Then segmentation function parameters are show below.\n","\n","*   points_per_side - The number of points to be sampled along one side of the image. The total number of points is points_per_side**2. If None, 'point_grids' must provide explicit point sampling.\n","*   points_per_batch - Sets the number of points run simultaneously by the model. Higher numbers may be faster but use more GPU memory.\n","*   pred_iou_tresh - A filtering threshold in [0,1], using the model's predicted mask quality.\n","*   stabilty_score_tresh - A filtering threshold in [0,1], using the stability of the mask under changes to the cutoff used to binarize the model's mask predictions.\n","*   stability_score_offset - The amount to shift the cutoff when calculated the stability score.\n","*   crop_n_layers - If >0, mask prediction will be run again on crops of the image. Sets the number of layers to run, where each layer has 2**i_layer number of image crops.\n","*   box_nms_tresh - The box IoU cutoff used by non-maximal suppression to filter duplicate masks.\n","*   crop_n_points_downscale_factor - The number of points-per-side sampled in layer\n","*   use_m2m - Whether to add a one step refinement using previous mask predictions.\n","\n"],"metadata":{"id":"BLlCg_WJ5N_s"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zUeeVNOxx9AG"},"outputs":[],"source":["# model_id = \"sam2-hiera-large\" #@param [\"sam2-hiera-tiny\", \"sam2-hiera-small\", \"sam2-hiera-base-plus\", \"sam2-hiera-large\"]\n","model = \"base_plus\" #@param  [\"tiny\", \"small\", \"base_plus\", \"large\"]\n","use_finetuned_model = True #@param {type:\"boolean\"}\n","\n","model_id = \"sam2-hiera-\" + model.replace(\"_\", \"-\")\n","\n","Sam2 = SamGeo2(\n","    model_id=model_id,\n","    automatic=True,\n","    output_mode='binary_mask',\n","    points_per_side=32,\n","    points_per_batch=64,\n","    pred_iou_thresh=0.7,\n","    stability_score_thresh=0.7,\n","    stability_score_offset=0.7,\n","    crop_n_layers=1,\n","    box_nms_thresh=0.7,\n","    crop_n_points_downscale_factor=2,\n","    min_mask_region_area=50.0,\n","    use_m2m=True\n","  )\n","\n","if use_finetuned_model:\n","  weights = \"finetuned_\" + model\n","  weights = eval(weights)\n","  res = Sam2.mask_generator.predictor.model.load_state_dict(weights)\n","  print(res)"]},{"cell_type":"markdown","source":["### Segment images"],"metadata":{"id":"MD9eymGKXpdK"}},{"cell_type":"code","source":["image = \"landsat\" #@param [\"naip\", \"landsat\", \"sentinel\"]\n","copy_to_drive = True #@param {type:\"boolean\"}\n","in_dir = image + \"/tiles/rgb_usa\"\n","if use_finetuned_model:\n","  model_type = \"finetuned\"\n","else:\n","  model_type = \"pretrained\"\n","\n","out_dir = image + \"/masks/rgb_\" + model_type + \"_\" + model\n","\n","\n","start_time = time.time()\n","\n","# Segment images\n","sam_generate_batch(\n","    sam=Sam2,\n","    in_dir=in_dir,\n","    out_dir=out_dir,\n","    vectorize=True)\n","\n","end_time = time.time()\n","\n","execution_time = end_time - start_time\n","print(f\"Execution time: {execution_time:.2f} seconds\")\n","\n","if copy_to_drive:\n","\n","  colab_file_path = out_dir + \"/merged_masks\"\n","  drive_tif_file_path = '/content/gdrive/MyDrive/Agriculture_tif/' + image + \"_\" + model_type + \"_\" + model + \".tif\"\n","  drive_shp_file_path = \"/content/gdrive/MyDrive/Agriculture_shp/\" + image + \"_\" + model_type + \"_\" + model\n","\n","  # Copy the tif file\n","  !cp {colab_file_path + \".tif\"} {drive_tif_file_path}\n","\n","  #Copy the shp files\n","  !cp {colab_file_path + \".cpg\"} {drive_shp_file_path + \".cpg\"}\n","  !cp {colab_file_path + \".dbf\"} {drive_shp_file_path + \".dbf\"}\n","  !cp {colab_file_path + \".prj\"} {drive_shp_file_path + \".prj\"}\n","  !cp {colab_file_path + \".shp\"} {drive_shp_file_path + \".shp\"}\n","  !cp {colab_file_path + \".shx\"} {drive_shp_file_path + \".shx\"}\n"],"metadata":{"id":"c8op7B9JYSNO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Validate delineation\n","To validate agricutural fields dlineation [ESA cropland dataset](https://developers.google.com/earth-engine/datasets/catalog/ESA_WorldCereal_2021_MARKERS_v100) will be used. Dataset conatins image representation of agricultural fields on USA trritory. Each pixel have 10m resoultion and can represent active or noactive fields. Since the goal is to delineate all fields both pixels values will be mrged into new binary layer and vactorise.\n","\n"],"metadata":{"id":"woU4G9XC5ugh"}},{"cell_type":"code","source":["def download_esa_cropland(aoi, start_date, end_date, filename, scale):\n","  \"\"\"\n","  Download ESA cropland dataset from Google Earth Engine.\n","\n","  aoi: geometry of area of interest, ee.Geometry\n","  start_date: date to start search for images\n","  end_date: date to end search for images\n","  filename: path to save image, str\n","  scale: scale to rescale image\n","  \"\"\"\n","\n","  # Load dataset as sum of active and inactive croplands\n","  dataset = (ee.ImageCollection('ESA/WorldCereal/2021/MARKERS/v100')\n","    .filterDate(start_date, end_date)\n","    .sum()\n","  )\n","\n","  dataset = dataset.clip(aoi)\n","\n","  cropLandcover = dataset.select('classification')\n","\n","  # Vectorise cropland image\n","  vectorised_croplandcover = cropLandcover.reduceToVectors(\n","        geometryType='polygon',\n","        reducer=ee.Reducer.countEvery(),\n","        scale=scale,\n","        maxPixels=1e13,\n","        geometry=aoi\n","    )\n","\n","  # Save cropland image\n","  save_ee_image(cropLandcover, filename, scale=scale, aoi=aoi, convert_to_int=True)\n","\n","  # Save cropland shapefile\n","  geemap.ee_to_shp(vectorised_croplandcover, filename + \".shp\")\n"],"metadata":{"id":"uV2TT1PV8dbP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define function to measure segmentation accuracy using intersection over union (IoU) metric also known as Jaccard's Index. Jaccard's Index formula:\n","\n","$J[A, B] = \\frac{|A \\cap B|}  {|A \\cup B|}$.\n","\n","The function loads two tif images and computes number of intersection and union pixels, next returns division result."],"metadata":{"id":"j77FKiX2XvvI"}},{"cell_type":"code","source":["import numpy as np\n","from PIL import Image\n","\n","# Raise limit of image pixels number\n","Image.MAX_IMAGE_PIXELS = 600000000\n","\n","def calculate_iou(image1_path, image2_path):\n","    \"\"\"\n","    Calculate intersection over union (IoU) between two binary images in TIFF format.\n","\n","    Parameters:\n","    - image1_path: Path to the first binary TIFF image.\n","    - image2_path: Path to the second binary TIFF image.\n","\n","    Returns:\n","    - iou: The IoU value between the two images.\n","    \"\"\"\n","\n","    # Load TIFF images using PIL\n","    image1 = np.array(Image.open(image1_path))\n","    image2 = np.array(Image.open(image2_path))\n","\n","    # Ensure both images have the same shape\n","    if image1.shape != image2.shape:\n","        print(image1.shape)\n","        print(image2.shape)\n","        raise ValueError(\"The input images must have the same dimensions.\")\n","\n","    # Convert images to binary to make sure that values are correct\n","    binary_image1 = image1 > 0\n","    binary_image2 = image2 > 0\n","\n","    # Calculate intersection and union\n","    intersection = np.sum(np.logical_and(binary_image1, binary_image2))  # Pixels where both are 1\n","    union = np.sum(np.logical_or(binary_image1, binary_image2))  # Pixels where either is 1\n","\n","    # Avoid division by zero\n","    if union == 0:\n","        return 0.0\n","\n","    # Calculate IoU\n","    iou = intersection / union\n","\n","    return iou"],"metadata":{"id":"XS40BbMkutPg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Download ESA cropland data in scales corresponding to segmented images, date is also filtered to be same as them."],"metadata":{"id":"_oYHvEURZzgt"}},{"cell_type":"code","source":["download_esa_cropland(aoi_usa, '2020-03-01', '2021-04-20', \"esa_croplands_06\", scale=0.6)\n","download_esa_cropland(aoi_usa, '2020-03-01', '2021-04-20', \"esa_croplands_10\", scale=10)\n","download_esa_cropland(aoi_usa, '2020-03-01', '2021-04-20', \"esa_croplands_30\", scale=30)"],"metadata":{"id":"r5TNf6TSnH4W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# SAM2 models names\n","models = ['Tiny', 'Small', 'Base+', 'Large']\n","\n","# SAM2 models accuracy scores\n","pretrained = []\n","finetuned = []\n","\n","pretrained.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/naip_pretrained_tiny.tif\", \"/content/esa_croplands_06.tif\"))\n","pretrained.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/naip_pretrained_small.tif\", \"/content/esa_croplands_06.tif\"))\n","pretrained.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/naip_pretrained_base_plus.tif\", \"/content/esa_croplands_06.tif\"))\n","pretrained.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/naip_pretrained_large.tif\", \"/content/esa_croplands_06.tif\"))\n","\n","finetuned.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/naip_finetuned_tiny.tif\", \"/content/esa_croplands_06.tif\"))\n","finetuned.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/naip_finetuned_small.tif\", \"/content/esa_croplands_06.tif\"))\n","finetuned.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/naip_finetuned_base_plus.tif\", \"/content/esa_croplands_06.tif\"))\n","finetuned.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/naip_finetuned_large.tif\", \"/content/esa_croplands_06.tif\"))\n","\n","print(pretrained)\n","print(finetuned)\n","\n","# X axis names arrange\n","x = np.arange(len(models))\n","\n","width = 0.35\n","\n","# Create plot\n","plt.bar(x - width/2, pretrained, width=width, label='Pre-Trained', color='#4C72BB')\n","plt.bar(x + width/2, finetuned, width=width, label='Fine-Tuned', color='#55BB68')\n","\n","# Add plot descriptions\n","plt.xlabel('Models')\n","plt.ylabel('Accuracy')\n","plt.title('Accuracy of SAM 2 models with NAIP images')\n","plt.xticks(x, models)\n","plt.legend()\n","\n","plt.savefig(\"NAIP_accuracy.png\", dpi=300)\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"IvuqToLFtE4x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SAM2 models names\n","models = ['Tiny', 'Small', 'Base+', 'Large']\n","\n","# SAM2 models accuracy scores\n","pretrained = []\n","finetuned = []\n","\n","pretrained.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/sentinel_pretrained_tiny.tif\", \"/content/esa_croplands_10.tif\"))\n","pretrained.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/sentinel_pretrained_small.tif\", \"/content/esa_croplands_10.tif\"))\n","pretrained.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/sentinel_pretrained_base_plus.tif\", \"/content/esa_croplands_10.tif\"))\n","pretrained.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/sentinel_pretrained_large.tif\", \"/content/esa_croplands_10.tif\"))\n","\n","finetuned.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/sentinel_finetuned_tiny.tif\", \"/content/esa_croplands_10.tif\"))\n","finetuned.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/sentinel_finetuned_small.tif\", \"/content/esa_croplands_10.tif\"))\n","finetuned.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/sentinel_finetuned_base_plus.tif\", \"/content/esa_croplands_10.tif\"))\n","finetuned.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/sentinel_finetuned_large.tif\", \"/content/esa_croplands_10.tif\"))\n","\n","print(pretrained)\n","print(finetuned)\n","\n","# X axis names arrange\n","x = np.arange(len(models))\n","\n","width = 0.35\n","\n","# Create plot\n","plt.bar(x - width/2, pretrained, width=width, label='Pre-Trained', color='#4C72BB')\n","plt.bar(x + width/2, finetuned, width=width, label='Fine-Tuned', color='#55BB68')\n","\n","# Add plot descriptions\n","plt.xlabel('Models')\n","plt.ylabel('Accuracy')\n","plt.title('Accuracy of SAM 2 models with Sentinel images')\n","plt.xticks(x, models)\n","plt.legend()\n","\n","plt.savefig(\"Sentinel_accuracy.png\", dpi=300)\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"uQY1Z5qGLP1y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SAM2 models names\n","models = ['Tiny', 'Small', 'Base+', 'Large']\n","import matplotlib.pyplot as plt\n","# SAM2 models accuracy scores\n","pretrained = []\n","finetuned = []\n","\n","pretrained.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/landsat_pretrained_tiny.tif\", \"/content/esa_croplands_30.tif\"))\n","pretrained.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/landsat_pretrained_small.tif\", \"/content/esa_croplands_30.tif\"))\n","pretrained.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/landsat_pretrained_base_plus.tif\", \"/content/esa_croplands_30.tif\"))\n","pretrained.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/landsat_pretrained_large.tif\", \"/content/esa_croplands_30.tif\"))\n","\n","finetuned.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/landsat_finetuned_tiny.tif\", \"/content/esa_croplands_30.tif\"))\n","finetuned.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/landsat_finetuned_small.tif\", \"/content/esa_croplands_30.tif\"))\n","finetuned.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/landsat_finetuned_base_plus.tif\", \"/content/esa_croplands_30.tif\"))\n","finetuned.append(calculate_iou(\"/content/gdrive/MyDrive/Agriculture_tif/landsat_finetuned_large.tif\", \"/content/esa_croplands_30.tif\"))\n","\n","print(pretrained)\n","print(finetuned)\n","\n","# X axis names arrange\n","x = np.arange(len(models))\n","\n","width = 0.35\n","\n","# Create plot\n","plt.bar(x - width/2, pretrained, width=width, label='Pre-Trained', color='#4C72BB')\n","plt.bar(x + width/2, finetuned, width=width, label='Fine-Tuned', color='#55BB68')\n","\n","# Add plot descriptions\n","plt.xlabel('Models')\n","plt.ylabel('Accuracy')\n","plt.title('Accuracy of SAM 2 models with Landsat images')\n","plt.xticks(x, models)\n","plt.legend()\n","\n","plt.savefig(\"Landsat_accuracy.png\", dpi=300)\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"hkjAajeQLQGV"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["2Aa7Ar0XfvGM","ZVUl0uWUwSem","gX-4OT55hawt","b6p8vjshP7WN","EEvjw6LDlhrz","bZ8-hx2WMa88"],"authorship_tag":"ABX9TyOro+dWcxVgk1Cw2vKWnSSc"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}